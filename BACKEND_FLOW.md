# Towncrier Backend Flow Documentation

## Overview
The Towncrier backend is an Express.js server that processes news articles, analyzes them for misinformation signals, and returns georeferenced data with sentiment analysis and media bias ratings. It uses a hybrid approach combining multiple data sources and ML models.

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (React)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    HTTP/REST API
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Express.js Backend Server                      â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                     Router Layer                           â”‚ â”‚
â”‚  â”‚  â€¢ /api/search (POST) - Main search endpoint              â”‚ â”‚
â”‚  â”‚  â€¢ /api/search/:id/results (GET) - Get results            â”‚ â”‚
â”‚  â”‚  â€¢ /api/health - Server health check                      â”‚ â”‚
â”‚  â”‚  â€¢ /api/legend - UI legend data                           â”‚ â”‚
â”‚  â”‚  â€¢ /api/sources - Available news sources                  â”‚ â”‚
â”‚  â”‚  â€¢ /api/trends/* - Google Trends analysis                â”‚ â”‚
â”‚  â”‚  â€¢ /api/serp/* - SERP analysis                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   Service Layer                            â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚            HybridFetcher                             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Combines NewsData.io & Google News               â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Fetches retractions & corrections                â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Deduplicates results                             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Timeout handling & fallback mechanism            â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                           â”‚                                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚            â”‚          â”‚            â”‚          â”‚    â”‚    â”‚ â”‚
â”‚  â”‚  â–¼            â–¼          â–¼            â–¼          â–¼    â–¼    â”‚ â”‚
â”‚  â”‚ NewsData   Google      Article     City      Sentiment  Biasâ”‚ â”‚
â”‚  â”‚ Fetcher    News        Text       Extractor  Analyzer  Lookupâ”‚
â”‚  â”‚          Scraper      Extractor                             â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚            StatusClassifier                          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Detects: Retractions, Corrections, etc.          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Uses misinformation signals & ML models          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Incorporates media bias data                     â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚            Google Trends Service                     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Fetches trend data via DataForSEO or Puppeteer  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Generates trend polygons for visualization       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Analyzes trend phases & comparisons              â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚            Jaccard Similarity Filter                 â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Removes off-topic noise                          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Keeps articles with word overlap                 â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                      GeoJSON Output
                    (Features + Properties)
                           â”‚
                      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                      â”‚ Frontend â”‚
                      â”‚   Map    â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Main Search Flow

### 1. **Search Endpoint** (`POST /api/search`)

**Input:**
```json
{
  "terms": ["keyword1", "keyword2", ...],
  "limit": 100,
  "sources": ["optional", "source", "ids"]
}
```

**Process:**
- Generate unique search ID
- Return 202 ACCEPTED immediately
- Process search asynchronously in background

---

### 2. **Article Fetching Phase**

#### Step 2.1: Hybrid Fetch
```
HybridFetcher.fetchArticles()
    â†“
    â”œâ”€â†’ Expand search terms:
    â”‚   â”œâ”€ Original: ["climate change"]
    â”‚   â”œâ”€ Retractions: ["retraction", "climate change"]
    â”‚   â””â”€ Corrections: ["correction", "climate change"]
    â”‚
    â”œâ”€â†’ For each term set, fetch from BOTH in parallel:
    â”‚   â”œâ”€â†’ NewsData.io API
    â”‚   â”‚   â”œâ”€ Timeout: 8 seconds
    â”‚   â”‚   â”œâ”€ Fallback: empty array
    â”‚   â”‚   â””â”€ Returns: Title, Description, Link, Source, etc.
    â”‚   â”‚
    â”‚   â””â”€â†’ Google News Scraper
    â”‚       â”œâ”€ Timeout: 10 seconds
    â”‚       â”œâ”€ Fallback: empty array
    â”‚       â””â”€ Returns: Similar structure
    â”‚
    â”œâ”€â†’ Combine & Deduplicate
    â”‚   â””â”€ Remove exact duplicates
    â”‚
    â””â”€â†’ Result: Array of HybridArticles
```

#### Step 2.2: Jaccard Similarity Filtering
```
Filter articles that share at least 1 word with other articles
    â”œâ”€ Removes completely off-topic noise
    â”œâ”€ Keeps thematically related content
    â””â”€ Example: 100 articles â†’ 85 articles (relevant)
```

---

### 3. **Content Enrichment Phase**

#### Step 3.1: Article Text Extraction
```
For each article:
    â”œâ”€ Check if content exists
    â”œâ”€ If missing:
    â”‚   â””â”€ Scrape from article.link using headless browser
    â”‚      (Uses node-readability or similar)
    â”‚
    â””â”€ Result: Full article content for analysis
```

#### Step 3.2: Media Bias Lookup
```
For each article:
    â”œâ”€ Load media-bias.csv (if not cached)
    â”‚   â””â”€ Parsed into cache: domain â†’ BiasRating
    â”‚
    â”œâ”€ Look up by source name (primary)
    â”‚   â”œâ”€ Exact match: "BBC News"
    â”‚   â”œâ”€ Short name: "BBC"
    â”‚   â””â”€ Fuzzy match: partial name matching
    â”‚
    â”œâ”€ Fallback: Look up by domain from article URL
    â”‚   â””â”€ Extract domain & match against cache
    â”‚
    â””â”€ Result:
        â”œâ”€ bias: -30 to +30 (-30 = liberal/left, +30 = conservative/right)
        â””â”€ factualReporting: "MIXED" | "HIGH" | "VERY_HIGH"
        
        ðŸ’» Console Output:
        âœ“ Media Bias Lookup - Source: "BBC News" | Bias: -5 | Factual Reporting: VERY_HIGH
```

#### Step 3.3: City Extraction
```
For each article:
    â”œâ”€ Input: title + description
    â”œâ”€ Extract primary geographic location
    â”œâ”€ Return: {
    â”‚   name: string,
    â”‚   latitude: number,
    â”‚   longitude: number,
    â”‚   confidence: 0-1
    â”‚ }
    â””â”€ Used for: Geovisualization on map
```

---

### 4. **Analysis Phase**

#### Step 4.1: Status Classification
```
classifyStatus(title + description + content, biasRating, factualReporting)
    â”‚
    â”œâ”€ Detect signals using ML models & keyword matching:
    â”‚   â”œâ”€ Retraction signals: "retract", "withdrawn", "removed", etc.
    â”‚   â”œâ”€ Correction signals: "correction", "amended", "erratum", etc.
    â”‚   â”œâ”€ Biased signals: Inflammatory language, extreme bias indicators
    â”‚   â””â”€ Misinformation signals: Falsehood patterns, dubious claims
    â”‚
    â”œâ”€ Classify into categories:
    â”‚   â”œâ”€ "retraction" â†’ Red circle
    â”‚   â”œâ”€ "correction" â†’ Orange square
    â”‚   â”œâ”€ "news-article" â†’ Green triangle
    â”‚   â”œâ”€ "biased-source" â†’ Purple hexagon
    â”‚   â””â”€ "untruthful-source" â†’ Pink diamond
    â”‚
    â””â”€ Result: {
        status: string,
        confidence: 0-1,
        reason: string,
        signals: string[]
      }
```

#### Step 4.2: Sentiment Analysis
```
sentiment.analyze(title + description + content)
    â”‚
    â”œâ”€ Run sentiment NLP analysis
    â”‚
    â””â”€ Result: {
        score: -N to +N,           // Absolute sentiment score
        comparative: -1 to 1,       // Normalized score
        sentimentLabel: "positive" | "negative" | "neutral"
      }

Valence Calculation:
    â””â”€ valence = Math.max(-1, Math.min(1, comparative * 2))
       â””â”€ Used for: Marker color gradient on map
           â”œâ”€ Red (-1): Most negative
           â”œâ”€ Gray (0): Neutral
           â””â”€ Blue (+1): Most positive
```

#### Step 4.3: GeoJSON Feature Creation
```
For each article, create Feature:
{
  type: "Feature",
  geometry: {
    type: "Point",
    coordinates: [longitude, latitude]
  },
  properties: {
    id: string,
    title: string,
    author: string,
    source: string,
    publishDate: ISO8601,
    link: URL,
    description: string,
    status: classification status,
    statusConfidence: 0-1,
    statusReason: string,
    detectedSignals: [...],
    city: string,
    confidence: 0-1 (city extraction confidence),
    sentiment: { score, comparative },
    sentimentLabel: string,
    valence: -1 to 1 (for color gradient),
    category: string,
    bias: -30 to 30 (optional),
    factualReporting: string (optional),
    firstArticleTime: timestamp (for animation)
  }
}
```

---

### 5. **Aggregation & Analytics Phase**

#### Step 5.1: Summary Statistics
```
Count across all articles:
    â”œâ”€ total: All articles processed
    â”œâ”€ retractions: Count by status
    â”œâ”€ corrections: Count by status
    â”œâ”€ newsArticles: Count by status
    â”œâ”€ biasedSources: Count by status
    â””â”€ untruthfulSources: Count by status
```

#### Step 5.2: Misinformation Metrics
```
analyzeMisinformationMetrics(all_classifications):
    â”‚
    â”œâ”€ High Confidence Incidents
    â”‚   â””â”€ Count where confidence > threshold
    â”‚
    â”œâ”€ Potential Misinformation
    â”‚   â””â”€ Count where multiple signals detected
    â”‚
    â”œâ”€ Misdirected Content
    â”‚   â””â”€ Count where location confidence is low
    â”‚
    â””â”€ Top Signals
        â””â”€ Most common misinformation indicators detected
           Example: [["fake news", 12], ["altered", 8], ...]
```

---

### 6. **Response Phase**

#### Step 6.1: Store in Cache
```
activeSearches[search_id] = {
  id: string,
  terms: string[],
  createdAt: timestamp,
  status: "complete",
  geojson: FeatureCollection,      // All features
  summary: SummaryStats,            // Aggregated counts
  misinformationMetrics: Metrics,  // Analytics
  sentimentScores: [...]            // Per-article sentiment
}
```

#### Step 6.2: Retrieve Results
```
GET /api/search/:id/results

Response:
{
  search_id: string,
  ready: boolean,
  geojson: {
    type: "FeatureCollection",
    features: [...]
  },
  summary: {
    total: number,
    retractions: number,
    corrections: number,
    newsArticles: number,
    biasedSources: number,
    untruthfulSources: number
  },
  misinformationMetrics: {
    highConfidenceIncidents: number,
    potentialMisinformation: number,
    misdirectedContent: number,
    topSignals: [[string, number], ...]
  }
}
```

---

## Service Details

### **HybridFetcher**
- **Purpose**: Combine multiple news sources for comprehensive coverage
- **Sources**: 
  - NewsData.io API (official data)
  - Google News Scraper (web scraping)
- **Features**:
  - Automatic fallback if one source fails
  - Search expansion for retractions/corrections
  - Deduplication of results
  - Timeout handling

### **StatusClassifier**
- **Purpose**: Categorize articles and detect misinformation
- **Categories**: retraction, correction, news-article, biased-source, untruthful-source
- **Detects**: 
  - Formal retractions
  - Corrections and amendments
  - Biased language patterns
  - Common misinformation indicators
  - Factual inconsistencies

### **MediaBiasLookup**
- **Data Source**: `server/data/media-bias.csv`
- **Matching Strategy**:
  1. Try source name (best for Google News)
  2. Try domain extraction
  3. Try partial matches
- **Output**: Bias rating (-30 to +30) + Factual reporting score
- **Console Output**: Logs each match found

### **CityExtractor**
- **Purpose**: Extract geographic location from article text
- **Returns**: City name + coordinates + confidence score
- **Used For**: Geovisualization on map

### **Sentiment Analysis**
- **Library**: `sentiment` npm package
- **Input**: Full article text
- **Output**: Sentiment score + comparative rating
- **Used For**: 
  - Marker color gradient (red = negative, blue = positive)
  - Trend analysis
  - Misinformation patterns

### **Jaccard Similarity**
- **Purpose**: Filter out off-topic noise
- **Threshold**: At least 1 word overlap
- **Result**: Removes completely unrelated articles while keeping thematic variations

### **Google Trends Service**
- **Purpose**: Analyze trends related to search terms
- **Data Sources**: 
  - DataForSEO API
  - Puppeteer web scraping
- **Outputs**:
  - Trend data over time
  - State-level trend polygons
  - Trend comparisons

---

## Data Flow Diagram

```
User Input (Search Terms)
        â†“
[POST /api/search] â†’ Return search_id (202 ACCEPTED)
        â†“
HybridFetcher (NewsData + Google News)
        â†“
Deduplicate
        â†“
Jaccard Similarity Filter
        â†“
Extract Article Content
        â†“
[Parallel Processing for each article]
â”œâ”€â†’ CityExtractor
â”œâ”€â†’ MediaBiasLookup (CSV) â†’ ðŸ’» Console Log
â”œâ”€â†’ StatusClassifier
â”œâ”€â†’ Sentiment Analysis
â””â”€â†’ Create GeoJSON Feature
        â†“
Aggregate Statistics
        â†“
Calculate Misinformation Metrics
        â†“
Store in Cache (activeSearches)
        â†“
[GET /api/search/:id/results] â†’ Return FeatureCollection + Analytics
```

---

## Performance Considerations

1. **Parallel Processing**: Articles processed in parallel for speed
2. **Async/Await**: Non-blocking I/O for API calls and web scraping
3. **In-Memory Cache**: Search results stored in process memory (not persisted)
4. **Timeouts**: 
   - NewsData.io: 8 seconds
   - Google News: 10 seconds
   - Falls back gracefully on timeout
5. **Streaming**: Content extraction happens in parallel, not sequential

---

## Error Handling

```
Search Endpoint
â”œâ”€ Network errors â†’ Fallback sources, return partial results
â”œâ”€ Timeout errors â†’ Use cached data or empty results
â”œâ”€ Parsing errors â†’ Skip malformed articles
â”œâ”€ Missing content â†’ Attempt web scraping, skip if fails
â””â”€ Database errors â†’ Return empty collection
```

---

## Console Output Examples

```
âœ“ Loaded media bias data for 427 sources from local CSV
âœ“ Media Bias Lookup - Source: "CNN" | Bias: -15 | Factual Reporting: HIGH
âœ“ Media Bias Lookup - Source: "Fox News" | Bias: 20 | Factual Reporting: MIXED
[Search] Jaccard filter: 100 â†’ 85 articles
[Search] Word overlap stats - Mean: 12.34 words, Min: 1, Max: 45
```

---

## API Endpoints Summary

| Method | Endpoint | Purpose |
|--------|----------|---------|
| POST | `/api/search` | Start new search (async) |
| GET | `/api/search/:id/results` | Get search results |
| GET | `/api/health` | Server health check |
| GET | `/api/legend` | UI legend configuration |
| GET | `/api/sources` | Available news sources |
| GET | `/api/trends/*` | Google Trends analysis |
| GET | `/api/serp/*` | SERP analysis |

---

## Database/Storage

- **Primary**: In-memory (process-specific)
- **CSV Data**: `server/data/media-bias.csv` (static, cached on load)
- **Persistence**: None (results lost on server restart)
- **Cache**: Search results expire after process restart

---

## Future Improvements

1. **Database Integration**: Persist search results to PostgreSQL/MongoDB
2. **Caching**: Redis for distributed caching
3. **Rate Limiting**: Implement API rate limits
4. **Authentication**: Add API key authentication
5. **Analytics**: Track popular searches and trends
6. **ML Models**: Fine-tuned models for better classification
7. **Real-time Updates**: WebSocket support for live results
8. **Source Expansion**: Add more news APIs and data sources
